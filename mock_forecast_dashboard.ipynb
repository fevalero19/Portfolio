{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5592219f",
   "metadata": {},
   "source": [
    "# Sample commodity yield forescast dashboard\n",
    "\n",
    "This notebook will generate synthetic but realistic crop yields and weather data to set up a mock dashboard for commodity yield forecasting using python only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc02730d",
   "metadata": {},
   "source": [
    "# 1Ô∏è‚É£ Imports and base configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "594abc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os  # üëà added import for os.path.join\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# ----------------------------\n",
    "# Global settings and reproducibility\n",
    "# ----------------------------\n",
    "np.random.seed(42)\n",
    "OUTDIR = \"output\"  # keep as string for os.path.join compatibility\n",
    "os.makedirs(os.path.join(\".\", OUTDIR), exist_ok=True)  # üëà replaced Path.mkdir\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Define hierarchy of geography\n",
    "# ----------------------------\n",
    "# Australia‚Äôs pea-growing example:\n",
    "# - 2 States\n",
    "# - 5 Regions (3 in WA, 2 in SA)\n",
    "# - 25 Municipalities total\n",
    "STATES = {\n",
    "    \"Western Australia\": {\n",
    "        \"regions\": {\n",
    "            \"Great Southern\": [\"Albany\", \"Denmark\", \"Plantagenet\", \"Cranbrook\", \"Broomehill-Tambellup\"],\n",
    "            \"Wheatbelt\": [\"Northam\", \"Toodyay\", \"York\", \"Beverley\", \"Quairading\"],\n",
    "            \"South Coast\": [\"Esperance\", \"Ravensthorpe\", \"Jerramungup\", \"Gnowangerup\", \"Kojonup\"],\n",
    "        }\n",
    "    },\n",
    "    \"South Australia\": {\n",
    "        \"regions\": {\n",
    "            \"Yorke Peninsula\": [\"Copper Coast\", \"Yorke Peninsula\", \"Barunga West\", \"Wakefield\", \"Wallaroo\"],\n",
    "            \"Mid North\": [\"Clare and Gilbert Valleys\", \"Goyder\", \"Light\", \"Mallala\", \"Peterborough\"],\n",
    "        }\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c646a2",
   "metadata": {},
   "source": [
    "# 2Ô∏è‚É£ Build geography and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bfd138fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_geo():\n",
    "    \"\"\"Create a table of all state/region/municipality combinations.\"\"\"\n",
    "    rows = []\n",
    "    for st, st_data in STATES.items():\n",
    "        for reg, munis in st_data[\"regions\"].items():\n",
    "            for m in munis:\n",
    "                rows.append({\"state\": st, \"region\": reg, \"municipality\": m})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def seasonal_sine(day_of_year, peak_day, amplitude, baseline):\n",
    "    \"\"\"Produce smooth yearly cycles (e.g., temperature/precipitation).\"\"\"\n",
    "    return baseline + amplitude * np.cos(2 * np.pi * (day_of_year - peak_day) / 365.25)\n",
    "\n",
    "def clamp(x, lo, hi):\n",
    "    \"\"\"Limit numeric arrays between lower and upper bounds.\"\"\"\n",
    "    return np.minimum(np.maximum(x, lo), hi)\n",
    "\n",
    "# Regional climate modifiers (e.g., wetter coast, warmer inland)\n",
    "REGION_CLIMATE = {\n",
    "    \"Great Southern\": dict(temp_offset=-1.0, precip_mult=1.1, ndvi_peak_day=250),\n",
    "    \"Wheatbelt\": dict(temp_offset=+1.0, precip_mult=0.9, ndvi_peak_day=240),\n",
    "    \"South Coast\": dict(temp_offset=-1.5, precip_mult=1.2, ndvi_peak_day=255),\n",
    "    \"Yorke Peninsula\": dict(temp_offset=0.0, precip_mult=1.0, ndvi_peak_day=245),\n",
    "    \"Mid North\": dict(temp_offset=+0.5, precip_mult=0.95, ndvi_peak_day=240),\n",
    "}\n",
    "\n",
    "# ----------------------------\n",
    "# Generate realistic daily weather data\n",
    "# ----------------------------\n",
    "def generate_daily_weather(geo_df, start_year=2016, end_year=2025):\n",
    "    \"\"\"\n",
    "    Simulate 10 years of daily weather per municipality with realistic\n",
    "    inter-annual anomalies (per year √ó region) to create variance across years.\n",
    "    \"\"\"\n",
    "    start_date = dt.date(start_year, 1, 1)\n",
    "    end_date = dt.date(end_year, 12, 31)\n",
    "    dates = pd.date_range(start_date, end_date, freq=\"D\")\n",
    "    doy = dates.dayofyear.values\n",
    "\n",
    "    # --- NEW: build a per-year √ó region anomaly table to amplify year-to-year variation ---\n",
    "    years = np.arange(start_year, end_year + 1)\n",
    "    anom_rows = []\n",
    "    for reg in REGION_CLIMATE.keys():\n",
    "        for y in years:\n",
    "            anom_rows.append({\n",
    "                \"region\": reg,\n",
    "                \"year\": y,\n",
    "                # precipitation anomaly multiplier (¬±15% typical)\n",
    "                \"precip_mult_year\": np.clip(np.random.normal(1.0, 0.15), 0.7, 1.4),\n",
    "                # temperature shift (¬∞C, ¬±1.0 typical)\n",
    "                \"temp_shift_year\": np.random.normal(0.0, 1.0),\n",
    "                # NDVI baseline shift (¬±0.03 typical)\n",
    "                \"ndvi_shift_year\": np.random.normal(0.0, 0.03),\n",
    "            })\n",
    "    year_anoms = pd.DataFrame(anom_rows)\n",
    "\n",
    "    all_records = []\n",
    "    for _, row in geo_df.iterrows():\n",
    "        st, reg, muni = row[\"state\"], row[\"region\"], row[\"municipality\"]\n",
    "        rc = REGION_CLIMATE[reg]\n",
    "\n",
    "        # Precompute static seasonal baselines (no per-year factor yet)\n",
    "        tavg_base0 = seasonal_sine(doy, 30, 7.5, 16.0 + rc[\"temp_offset\"])\n",
    "        precip_base0 = seasonal_sine(doy, 210, 2.5, 1.2).clip(min=0.1)\n",
    "        ndvi_peak_day = rc[\"ndvi_peak_day\"]\n",
    "\n",
    "        # For each year, apply a distinct anomaly to get cross-year variability at the same week\n",
    "        for y in years:\n",
    "            # indices for this year within the full date range\n",
    "            mask_y = (dates.year == y)\n",
    "            doy_y = doy[mask_y]\n",
    "\n",
    "            # grab anomalies for (region, year)\n",
    "            a = year_anoms[(year_anoms[\"region\"] == reg) & (year_anoms[\"year\"] == y)].iloc[0]\n",
    "\n",
    "            # Temperature (¬∞C): add year shift\n",
    "            tavg_base = tavg_base0[mask_y] + a[\"temp_shift_year\"]\n",
    "            tmin = tavg_base - 5 + np.random.normal(0, 1.2, mask_y.sum())\n",
    "            tmax = tavg_base + 7 + np.random.normal(0, 1.5, mask_y.sum())\n",
    "            tavg = (tmin + tmax) / 2\n",
    "\n",
    "            # Precipitation (mm): seasonal gamma with per-region & per-year multipliers\n",
    "            precip = np.random.gamma(1.5, precip_base0[mask_y])\n",
    "            precip *= rc[\"precip_mult\"] * a[\"precip_mult_year\"]\n",
    "            precip = clamp(precip, 0, 40)\n",
    "\n",
    "            # Soil moisture: smoothed function of precip\n",
    "            soil_mo = np.zeros(mask_y.sum())\n",
    "            for i in range(1, mask_y.sum()):\n",
    "                soil_mo[i] = 0.1 * precip[i] + 0.9 * soil_mo[i - 1]\n",
    "            sm = clamp(40 + soil_mo * 1.5 + np.random.normal(0, 3, mask_y.sum()), 10, 95)\n",
    "\n",
    "            # NDVI: peaked season + year shift + humidity influence\n",
    "            ndvi = (0.2\n",
    "                    + 0.25 * np.exp(-((doy_y - ndvi_peak_day) ** 2) / (2 * 25**2))\n",
    "                    + a[\"ndvi_shift_year\"]\n",
    "                    + 0.04 * (sm / 100)\n",
    "                    + np.random.normal(0, 0.03, mask_y.sum()))\n",
    "            ndvi = clamp(ndvi, 0.05, 0.95)\n",
    "\n",
    "            all_records.append(pd.DataFrame({\n",
    "                \"date\": dates[mask_y],\n",
    "                \"state\": st,\n",
    "                \"region\": reg,\n",
    "                \"municipality\": muni,\n",
    "                \"precip_mm\": precip,\n",
    "                \"tmin_c\": tmin,\n",
    "                \"tmax_c\": tmax,\n",
    "                \"tavg_c\": tavg,\n",
    "                \"soil_rel_humidity_pct\": sm,\n",
    "                \"ndvi\": ndvi,\n",
    "            }))\n",
    "\n",
    "    df = pd.concat(all_records, ignore_index=True)\n",
    "    df[\"year\"] = df[\"date\"].dt.year\n",
    "    df[\"week\"] = df[\"date\"].dt.isocalendar().week.astype(int)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0b6ffa",
   "metadata": {},
   "source": [
    "# 3Ô∏è‚É£ Simulate seasonal yields & weekly features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "90b38921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 3Ô∏è‚É£ Simulate seasonal yields & weekly features\n",
    "# ----------------------------\n",
    "\n",
    "# Define crops and coefficients for synthetic yield generation\n",
    "CROPS = {\n",
    "    \"faba_bean\": dict(base=2.2, precip_beta=0.0022, temp_beta=-0.03, ndvi_beta=2.8, moist_beta=0.01),\n",
    "    \"chickpea\":  dict(base=1.6, precip_beta=0.0016, temp_beta=-0.02, ndvi_beta=2.1, moist_beta=0.008),\n",
    "    \"lentil\":    dict(base=1.8, precip_beta=0.0019, temp_beta=-0.022, ndvi_beta=2.3, moist_beta=0.009),\n",
    "}\n",
    "\n",
    "# Typical growing season (weeks)\n",
    "SEASON_WEEKS = list(range(18, 49))\n",
    "\n",
    "def build_seasonal_summaries(daily):\n",
    "    \"\"\"Aggregate daily data by season to produce one row per municipality-year.\"\"\"\n",
    "    return (daily[daily[\"week\"].isin(SEASON_WEEKS)]\n",
    "            .groupby([\"state\", \"region\", \"municipality\", \"year\"])\n",
    "            .agg(\n",
    "                precip_season=(\"precip_mm\", \"sum\"),\n",
    "                tavg_season=(\"tavg_c\", \"mean\"),\n",
    "                soil_moist_season=(\"soil_rel_humidity_pct\", \"mean\"),\n",
    "                ndvi_season=(\"ndvi\", \"mean\"),\n",
    "            )\n",
    "            .reset_index())\n",
    "\n",
    "def synthesize_yields(seasonal):\n",
    "    \"\"\"\n",
    "    Simulate crop yields as a function of seasonal conditions,\n",
    "    with NO direct precipitation effect (as requested).\n",
    "    We keep temperature, NDVI and soil moisture; increase NDVI/moisture\n",
    "    sensitivity a bit and keep noise modest for clearer single-variable signal.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for _, r in seasonal.iterrows():\n",
    "        for crop, pars in CROPS.items():\n",
    "            base = pars[\"base\"]\n",
    "\n",
    "            # y = base + (precip term) + (temp) + (ndvi) + (moist)\n",
    "            y = (base\n",
    "                 + (-0.028) * (r[\"tavg_season\"] - 22)       # temp effect\n",
    "                 + 3.6 * (r[\"ndvi_season\"] - 0.35)          # ‚Üë NDVI sensitivity\n",
    "                 + 0.014 * (r[\"soil_moist_season\"] - 45))   # ‚Üë moisture sensitivity\n",
    "\n",
    "            # Modest noise so R¬≤ reflects true signal but isn‚Äôt perfect\n",
    "            y += np.random.normal(0, 0.12)\n",
    "\n",
    "            # Crop-specific plausible ranges\n",
    "            lo_hi = {\"faba_bean\": (1.2, 4.2), \"chickpea\": (0.8, 3.2), \"lentil\": (0.9, 3.2)}[crop]\n",
    "            y = float(clamp(y, lo_hi[0], lo_hi[1]))\n",
    "\n",
    "            rows.append(dict(\n",
    "                state=r[\"state\"], region=r[\"region\"], municipality=r[\"municipality\"],\n",
    "                year=int(r[\"year\"]), crop=crop, yield_t_ha=y\n",
    "            ))\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Weekly features for model training\n",
    "# ----------------------------\n",
    "def build_weekly_features(df_daily, feature_col, agg_level=\"municipality\"):\n",
    "    \"\"\"Aggregate daily variable to weekly-to-date and attach 'unit' (geo name).\"\"\"\n",
    "    if agg_level == \"municipality\":\n",
    "        group = [\"state\", \"region\", \"municipality\", \"year\", \"week\"]\n",
    "        geo_year = [\"state\", \"region\", \"municipality\", \"year\"]\n",
    "        unit_col = \"municipality\"  # üëà this will be used in dashboard filtering\n",
    "    elif agg_level == \"region\":\n",
    "        group = [\"state\", \"region\", \"year\", \"week\"]\n",
    "        geo_year = [\"state\", \"region\", \"year\"]\n",
    "        unit_col = \"region\"\n",
    "    elif agg_level == \"state\":\n",
    "        group = [\"state\", \"year\", \"week\"]\n",
    "        geo_year = [\"state\", \"year\"]\n",
    "        unit_col = \"state\"\n",
    "\n",
    "    df = df_daily[df_daily[\"week\"].isin(SEASON_WEEKS)].copy()\n",
    "    weekly = df.groupby(group, as_index=False).agg({\n",
    "        feature_col: (\"sum\" if \"precip\" in feature_col else \"mean\")\n",
    "    })\n",
    "    weekly = weekly.sort_values(geo_year + [\"week\"]).reset_index(drop=True)\n",
    "\n",
    "    # Compute cumulative or running mean features\n",
    "    def agg_to_date(x):\n",
    "        return x.cumsum() if \"precip\" in feature_col else x.expanding().mean()\n",
    "    weekly[f\"{feature_col}_to_date\"] = weekly.groupby(geo_year)[feature_col].transform(agg_to_date)\n",
    "\n",
    "    # Add the 'unit' field for the dashboard to filter by region/state/municipality\n",
    "    weekly[\"unit\"] = weekly[unit_col]\n",
    "    return weekly[geo_year + [\"week\", f\"{feature_col}_to_date\", \"unit\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255cbd92",
   "metadata": {},
   "source": [
    "# 4Ô∏è‚É£ Modeling and dashboard setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "952401f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 4Ô∏è‚É£\n",
    "# 4Ô∏è‚É£ Modeling and dashboard setup (per-unit metrics, no squared=)\n",
    "# ----------------------------\n",
    "\n",
    "FEATURES = [\"precip_mm\", \"tmin_c\", \"tmax_c\", \"tavg_c\", \"soil_rel_humidity_pct\", \"ndvi\"]\n",
    "TRAIN_YEARS = list(range(2016, 2021))\n",
    "VAL_YEARS   = list(range(2021, 2024))\n",
    "TEST_YEARS  = list(range(2024, 2026))\n",
    "\n",
    "def aggregate_yields_with_unit(df_yields, agg_level=\"municipality\"):\n",
    "    \"\"\"Aggregate yields by chosen level and attach a 'unit' name.\"\"\"\n",
    "    if agg_level == \"municipality\":\n",
    "        keys, unit_col = [\"state\",\"region\",\"municipality\",\"year\",\"crop\"], \"municipality\"\n",
    "    elif agg_level == \"region\":\n",
    "        keys, unit_col = [\"state\",\"region\",\"year\",\"crop\"], \"region\"\n",
    "    else:\n",
    "        keys, unit_col = [\"state\",\"year\",\"crop\"], \"state\"\n",
    "    y = df_yields.groupby(keys, as_index=False)[\"yield_t_ha\"].mean()\n",
    "    y[\"unit\"] = y[unit_col]\n",
    "    return y\n",
    "\n",
    "def join_keys_for(agg_level):\n",
    "    \"\"\"Utility to define join keys per level.\"\"\"\n",
    "    if agg_level == \"municipality\": return [\"state\", \"region\", \"municipality\", \"year\"]\n",
    "    elif agg_level == \"region\": return [\"state\", \"region\", \"year\"]\n",
    "    else: return [\"state\", \"year\"]\n",
    "\n",
    "def fit_models(weather_daily, yields_yearly):\n",
    "    \"\"\"\n",
    "    Train linear regressions at the finest requested granularity:\n",
    "      - one model per (crop, feature, aggregation, unit, week).\n",
    "    Each model is trained on that unit's TRAIN_YEARS only, then evaluated on that unit's VAL/TEST years.\n",
    "    \"\"\"\n",
    "    metrics_rows, forecast_rows = [], []\n",
    "\n",
    "    for agg_level in [\"municipality\", \"region\", \"state\"]:\n",
    "        # Yields aggregated to chosen level, preserving 'unit'\n",
    "        Y_all = aggregate_yields_with_unit(yields_yearly, agg_level)\n",
    "\n",
    "        for feat in FEATURES:\n",
    "            # Weekly-to-date feature, preserving 'unit'\n",
    "            X_all = build_weekly_features(weather_daily, feat, agg_level)\n",
    "\n",
    "            for crop in CROPS.keys():\n",
    "                # Merge yields (per unit) with features (per unit-week)\n",
    "                keys = join_keys_for(agg_level)\n",
    "                df = (\n",
    "                    Y_all[Y_all[\"crop\"] == crop]\n",
    "                    .merge(X_all, on=keys + [\"unit\"], how=\"inner\")\n",
    "                )\n",
    "\n",
    "                # --- Train a separate model for EACH unit ---\n",
    "                for unit_value, df_unit in df.groupby(\"unit\", sort=False):\n",
    "\n",
    "                    # Iterate across weeks in the season (each week = different cumulative feature)\n",
    "                    for w in SEASON_WEEKS:\n",
    "                        dfw = df_unit[df_unit[\"week\"] == w].copy()\n",
    "                        if dfw.empty:\n",
    "                            continue\n",
    "\n",
    "                        # Split by year for THIS unit\n",
    "                        tr = dfw[dfw[\"year\"].isin(TRAIN_YEARS)]\n",
    "                        va = dfw[dfw[\"year\"].isin(VAL_YEARS)]\n",
    "                        te = dfw[dfw[\"year\"].isin(TEST_YEARS)]\n",
    "\n",
    "                        # Need enough samples to fit a 1-parameter linear model\n",
    "                        if len(tr) < 3:  # 3+ years recommended for stability\n",
    "                            # Still record rows with NaN/0 metrics so lines can render if desired\n",
    "                            def _mk_zero(set_name):\n",
    "                                metrics_rows.append(dict(\n",
    "                                    crop=crop, variable=feat, aggregation=agg_level, unit=unit_value,\n",
    "                                    week=int(w), set=set_name, r2=0.0, r2_adj=0.0,\n",
    "                                    rmse=np.nan, mean_pred_yield_t_ha=np.nan\n",
    "                                ))\n",
    "                            for set_name in [\"train\", \"val\", \"test\"]:\n",
    "                                _mk_zero(set_name)\n",
    "                            forecast_rows.append(dict(\n",
    "                                crop=crop, variable=feat, aggregation=agg_level, unit=unit_value,\n",
    "                                week=int(w), mean_pred_yield_test=np.nan, mean_pred_yield_val=np.nan\n",
    "                            ))\n",
    "                            continue\n",
    "\n",
    "                        # Fit the model on THIS unit's training rows\n",
    "                        model = LinearRegression().fit(tr[[f\"{feat}_to_date\"]], tr[\"yield_t_ha\"])\n",
    "\n",
    "                        # Robust evaluation helper (never returns NaN R¬≤)\n",
    "                        def eval_set(sub):\n",
    "                            if sub.empty:\n",
    "                                return dict(r2=0.0, r2_adj=0.0, rmse=np.nan, mean_pred=np.nan)\n",
    "                            yp = model.predict(sub[[f\"{feat}_to_date\"]])\n",
    "                            y_true = sub[\"yield_t_ha\"].values\n",
    "\n",
    "                            # Guard: constant target or too few samples ‚Üí R¬≤ undefined ‚Üí force 0.0\n",
    "                            if len(y_true) < 2 or np.allclose(np.var(y_true), 0.0):\n",
    "                                r2 = 0.0\n",
    "                                r2_adj = 0.0\n",
    "                            else:\n",
    "                                r2 = r2_score(y_true, yp)\n",
    "\n",
    "                                # Clamp negative R¬≤ values to 0\n",
    "                                if np.isnan(r2) or r2 < 0:\n",
    "                                    r2 = 0.0\n",
    "\n",
    "                                # Adjusted R¬≤ (also clamped to ‚â• 0)\n",
    "                                n = len(y_true); p = 1\n",
    "                                if n > p + 1:\n",
    "                                    r2_adj = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "                                else:\n",
    "                                    r2_adj = r2\n",
    "                                if np.isnan(r2_adj) or r2_adj < 0:\n",
    "                                    r2_adj = 0.0\n",
    "\n",
    "                            mse = mean_squared_error(y_true, yp)   # <- no squared= param\n",
    "                            rmse = np.sqrt(mse)\n",
    "                            return dict(r2=float(r2), r2_adj=float(r2_adj), rmse=float(rmse), mean_pred=float(np.nanmean(yp)))\n",
    "\n",
    "                        # Evaluate for this unit\n",
    "                        tr_m, va_m, te_m = eval_set(tr), eval_set(va), eval_set(te)\n",
    "\n",
    "                        # Record metrics rows per set\n",
    "                        for set_name, m in [(\"train\", tr_m), (\"val\", va_m), (\"test\", te_m)]:\n",
    "                            metrics_rows.append(dict(\n",
    "                                crop=crop, variable=feat, aggregation=agg_level, unit=unit_value,\n",
    "                                week=int(w), set=set_name,\n",
    "                                r2=m[\"r2\"], r2_adj=m[\"r2_adj\"], rmse=m[\"rmse\"],\n",
    "                                mean_pred_yield_t_ha=m[\"mean_pred\"]\n",
    "                            ))\n",
    "\n",
    "                        # Record forecasts for plotting\n",
    "                        forecast_rows.append(dict(\n",
    "                            crop=crop, variable=feat, aggregation=agg_level, unit=unit_value,\n",
    "                            week=int(w),\n",
    "                            mean_pred_yield_test=te_m[\"mean_pred\"],\n",
    "                            mean_pred_yield_val=va_m[\"mean_pred\"]\n",
    "                        ))\n",
    "\n",
    "    # Assemble outputs\n",
    "    metrics_df = pd.DataFrame(metrics_rows)\n",
    "    forecast_df = pd.DataFrame(forecast_rows).drop_duplicates(\n",
    "        subset=[\"crop\",\"variable\",\"aggregation\",\"unit\",\"week\"]\n",
    "    )\n",
    "\n",
    "    plot_df = metrics_df.merge(\n",
    "        forecast_df, on=[\"crop\",\"variable\",\"aggregation\",\"unit\",\"week\"], how=\"left\"\n",
    "    )\n",
    "    return metrics_df, plot_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12763ba",
   "metadata": {},
   "source": [
    "# 5Ô∏è‚É£ Plotly/Dash dashboard (two independent TEST panels) + open in browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc0333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 5Ô∏è‚É£\n",
    "# 5Ô∏è‚É£ Plotly/Dash dashboard (two TEST panels) + launcher using app.run(...)\n",
    "# ----------------------------\n",
    "def build_dashboard(plot_df):\n",
    "    \"\"\"\n",
    "    Two-panel dashboard where BOTH plots use the TEST set.\n",
    "    Each panel has its OWN controls (Crop, Variable, Aggregation, Unit).\n",
    "    No CSS injection; dropdowns keep simple inline 'color: black' for control text.\n",
    "    \"\"\"\n",
    "    import dash\n",
    "    from dash import dcc, html, Input, Output\n",
    "    from plotly.subplots import make_subplots\n",
    "    import plotly.graph_objects as go\n",
    "    import pandas as pd\n",
    "\n",
    "    feature_cols = [\"precip_mm\", \"tmin_c\", \"tmax_c\", \"tavg_c\", \"soil_rel_humidity_pct\", \"ndvi\"]\n",
    "    aggs_available = [\"municipality\", \"region\", \"state\"]\n",
    "    crops = sorted(plot_df['crop'].unique().tolist())\n",
    "    has_unit_col = \"unit\" in plot_df.columns\n",
    "\n",
    "    def unit_options_for(agg: str):\n",
    "        \"\"\"Return list of available units for a given aggregation level.\"\"\"\n",
    "        if not has_unit_col:\n",
    "            return [\"All\"]\n",
    "        opts = (plot_df.loc[plot_df[\"aggregation\"] == agg, \"unit\"]\n",
    "                        .dropna().drop_duplicates().sort_values().tolist())\n",
    "        return opts if opts else [\"All\"]\n",
    "\n",
    "    app = dash.Dash(__name__)\n",
    "\n",
    "    def test_series_for(crop, var_sel, agg_sel, unit_value):\n",
    "        sel = (\n",
    "            (plot_df[\"crop\"] == crop) &\n",
    "            (plot_df[\"variable\"] == var_sel) &\n",
    "            (plot_df[\"aggregation\"] == agg_sel) &\n",
    "            (plot_df[\"set\"] == \"test\")\n",
    "        )\n",
    "        df = plot_df.loc[sel].copy()\n",
    "        if has_unit_col and pd.notna(unit_value) and unit_value != \"All\":\n",
    "            df = df[df[\"unit\"] == unit_value]\n",
    "        df = df.sort_values(\"week\")\n",
    "\n",
    "        # Coerce numeric & fill NaNs so the line always draws\n",
    "        w = df[\"week\"].astype(int)\n",
    "        y_pred = pd.to_numeric(df[\"mean_pred_yield_test\"], errors=\"coerce\").astype(float)\n",
    "        r2_adj = pd.to_numeric(df[\"r2_adj\"], errors=\"coerce\").astype(float).fillna(0.0)\n",
    "\n",
    "        return w, y_pred, r2_adj\n",
    "\n",
    "    app.layout = html.Div([\n",
    "        html.H2(\"Crop Yield Forecast vs Model Performance (Weekly) ‚Äî TEST only\"),\n",
    "\n",
    "        # ====== Panel A (Top) ======\n",
    "        html.Div([\n",
    "            html.Div([\n",
    "                html.Strong(\"Top plot (TEST) controls\"),\n",
    "\n",
    "                html.Label(\"Crop\"),\n",
    "                dcc.Dropdown(\n",
    "                    options=[{\"label\": c.replace(\"_\",\" \").title(), \"value\": c} for c in crops],\n",
    "                    value=crops[0], id=\"crop-dd-a\", clearable=False,\n",
    "                    style={\"width\": \"220px\", \"color\": \"black\"},\n",
    "                ),\n",
    "\n",
    "                html.Label(\"Variable\"),\n",
    "                dcc.Dropdown(\n",
    "                    options=[{\"label\": v, \"value\": v} for v in feature_cols],\n",
    "                    value=\"ndvi\", id=\"var-dd-a\", clearable=False,\n",
    "                    style={\"width\": \"220px\", \"color\": \"black\"},\n",
    "                ),\n",
    "\n",
    "                html.Label(\"Aggregation\"),\n",
    "                dcc.Dropdown(\n",
    "                    options=[{\"label\": a.title(), \"value\": a} for a in aggs_available],\n",
    "                    value=\"municipality\", id=\"agg-dd-a\", clearable=False,\n",
    "                    style={\"width\": \"220px\", \"color\": \"black\"},\n",
    "                ),\n",
    "\n",
    "                html.Label(\"Unit\"),\n",
    "                dcc.Dropdown(\n",
    "                    options=[{\"label\": u, \"value\": u} for u in unit_options_for(\"municipality\")],\n",
    "                    value=unit_options_for(\"municipality\")[0], id=\"unit-dd-a\", clearable=False,\n",
    "                    style={\"width\": \"260px\", \"color\": \"black\"},\n",
    "                ),\n",
    "            ], style={\"display\":\"flex\",\"gap\":\"16px\",\"alignItems\":\"center\",\"flexWrap\":\"wrap\",\"marginBottom\":\"8px\"}),\n",
    "\n",
    "            dcc.Graph(id=\"weekly-fig-a\", style={\"height\":\"400px\"}),\n",
    "        ], style={\"marginBottom\": \"24px\"}),\n",
    "\n",
    "        # ====== Panel B (Bottom) ======\n",
    "        html.Div([\n",
    "            html.Div([\n",
    "                html.Strong(\"Bottom plot (TEST) controls\"),\n",
    "\n",
    "                html.Label(\"Crop\"),\n",
    "                dcc.Dropdown(\n",
    "                    options=[{\"label\": c.replace(\"_\",\" \").title(), \"value\": c} for c in crops],\n",
    "                    value=crops[0], id=\"crop-dd-b\", clearable=False,\n",
    "                    style={\"width\": \"220px\", \"color\": \"black\"},\n",
    "                ),\n",
    "\n",
    "                html.Label(\"Variable\"),\n",
    "                dcc.Dropdown(\n",
    "                    options=[{\"label\": v, \"value\": v} for v in feature_cols],\n",
    "                    value=\"ndvi\", id=\"var-dd-b\", clearable=False,\n",
    "                    style={\"width\": \"220px\", \"color\": \"black\"},\n",
    "                ),\n",
    "\n",
    "                html.Label(\"Aggregation\"),\n",
    "                dcc.Dropdown(\n",
    "                    options=[{\"label\": a.title(), \"value\": a} for a in aggs_available],\n",
    "                    value=\"region\", id=\"agg-dd-b\", clearable=False,\n",
    "                    style={\"width\": \"220px\", \"color\": \"black\"},\n",
    "                ),\n",
    "\n",
    "                html.Label(\"Unit\"),\n",
    "                dcc.Dropdown(\n",
    "                    options=[{\"label\": u, \"value\": u} for u in unit_options_for(\"region\")],\n",
    "                    value=unit_options_for(\"region\")[0], id=\"unit-dd-b\", clearable=False,\n",
    "                    style={\"width\": \"260px\", \"color\": \"black\"},\n",
    "                ),\n",
    "            ], style={\"display\":\"flex\",\"gap\":\"16px\",\"alignItems\":\"center\",\"flexWrap\":\"wrap\",\"marginBottom\":\"8px\"}),\n",
    "\n",
    "            dcc.Graph(id=\"weekly-fig-b\", style={\"height\":\"400px\"}),\n",
    "        ]),\n",
    "    ])\n",
    "\n",
    "    # Sync Unit options with Aggregation (Panel A)\n",
    "    @app.callback(\n",
    "        Output(\"unit-dd-a\", \"options\"), Output(\"unit-dd-a\", \"value\"),\n",
    "        Input(\"agg-dd-a\", \"value\"),\n",
    "    )\n",
    "    def sync_units_a(agg_value):\n",
    "        opts = unit_options_for(agg_value)\n",
    "        return ([{\"label\": u, \"value\": u} for u in opts], opts[0])\n",
    "\n",
    "    # Sync Unit options with Aggregation (Panel B)\n",
    "    @app.callback(\n",
    "        Output(\"unit-dd-b\", \"options\"), Output(\"unit-dd-b\", \"value\"),\n",
    "        Input(\"agg-dd-b\", \"value\"),\n",
    "    )\n",
    "    def sync_units_b(agg_value):\n",
    "        opts = unit_options_for(agg_value)\n",
    "        return ([{\"label\": u, \"value\": u} for u in opts], opts[0])\n",
    "\n",
    "    # Update Top plot (TEST)\n",
    "    @app.callback(\n",
    "        Output(\"weekly-fig-a\", \"figure\"),\n",
    "        Input(\"crop-dd-a\", \"value\"), Input(\"var-dd-a\", \"value\"),\n",
    "        Input(\"agg-dd-a\", \"value\"), Input(\"unit-dd-a\", \"value\"),\n",
    "    )\n",
    "    def update_fig_a(crop_a, var_a, agg_a, unit_a):\n",
    "        w, y_pred, r2a = test_series_for(crop_a, var_a, agg_a, unit_a)\n",
    "        fig = make_subplots(rows=1, cols=1, specs=[[{\"secondary_y\": True}]])\n",
    "        fig.add_trace(go.Scatter(x=w, y=y_pred, mode=\"lines+markers\", name=\"Predicted yield (t/ha) ‚Äî Test\"), secondary_y=False)\n",
    "        fig.add_trace(go.Scatter(x=w, y=r2a, mode=\"lines+markers\", name=\"Adj. R¬≤ ‚Äî Test\"), secondary_y=True)\n",
    "        fig.update_layout(title=f\"TEST ‚Äî {crop_a.replace('_',' ').title()} | {var_a} | {agg_a.title()} [{unit_a}]\",\n",
    "                          height=400, legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.2, xanchor=\"center\", x=0.5))\n",
    "        fig.update_xaxes(title_text=\"Week (18‚Äì48)\")\n",
    "        fig.update_yaxes(title_text=\"Predicted Yield (t/ha)\", secondary_y=False)\n",
    "        fig.update_yaxes(title_text=\"Adjusted R¬≤\", secondary_y=True)\n",
    "        return fig\n",
    "\n",
    "    # Update Bottom plot (TEST)\n",
    "    @app.callback(\n",
    "        Output(\"weekly-fig-b\", \"figure\"),\n",
    "        Input(\"crop-dd-b\", \"value\"), Input(\"var-dd-b\", \"value\"),\n",
    "        Input(\"agg-dd-b\", \"value\"), Input(\"unit-dd-b\", \"value\"),\n",
    "    )\n",
    "    def update_fig_b(crop_b, var_b, agg_b, unit_b):\n",
    "        w, y_pred, r2b = test_series_for(crop_b, var_b, agg_b, unit_b)\n",
    "        fig = make_subplots(rows=1, cols=1, specs=[[{\"secondary_y\": True}]])\n",
    "        fig.add_trace(go.Scatter(x=w, y=y_pred, mode=\"lines+markers\", name=\"Predicted yield (t/ha) ‚Äî Test\"), secondary_y=False)\n",
    "        fig.add_trace(go.Scatter(x=w, y=r2b, mode=\"lines+markers\", name=\"Adj. R¬≤ ‚Äî Test\"), secondary_y=True)\n",
    "        fig.update_layout(title=f\"TEST ‚Äî {crop_b.replace('_',' ').title()} | {var_b} | {agg_b.title()} [{unit_b}]\",\n",
    "                          height=400, legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.2, xanchor=\"center\", x=0.5))\n",
    "        fig.update_xaxes(title_text=\"Week (18‚Äì48)\")\n",
    "        fig.update_yaxes(title_text=\"Predicted Yield (t/ha)\", secondary_y=False)\n",
    "        fig.update_yaxes(title_text=\"Adjusted R¬≤\", secondary_y=True)\n",
    "        return fig\n",
    "\n",
    "    return app\n",
    "\n",
    "# üëâ Launcher: open in a browser and run using app.run(...)\n",
    "def launch_dashboard_in_browser(plot_df, host=\"127.0.0.1\", port=8050):\n",
    "    import webbrowser, threading\n",
    "    app = build_dashboard(plot_df)\n",
    "    url = f\"http://{host}:{port}\"\n",
    "    threading.Timer(1.0, lambda: webbrowser.open(url)).start()   # open browser after a short delay\n",
    "    app.run(host=host, port=port, debug=False)                   # NOTE: using app.run(...), not run_server\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8036c9d8",
   "metadata": {},
   "source": [
    "# 6Ô∏è‚É£ Pipeline runner (Jupyter): generate data, train models, save CSVs, launch dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f4d07d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Saved: ./output/au_crop_weather_daily.csv\n",
      "‚úì Saved: ./output/au_crop_yields_yearly.csv\n",
      "‚úì Saved: ./output/model_weekly_metrics_allsets.csv\n",
      "‚úì Saved: ./output/model_weekly_metrics_and_forecasts.csv\n"
     ]
    }
   ],
   "source": [
    "# Run 6Ô∏è‚É£\n",
    "# 6Ô∏è‚É£ Pipeline runner (Jupyter): generate data, train models, save CSVs, launch dashboard\n",
    "# ----------------------------\n",
    "import os  # ensure available for os.path.join\n",
    "\n",
    "# 1) Build the geography table (25 municipalities across 5 regions & 2 states)\n",
    "geo_df = build_geo()\n",
    "\n",
    "# 2) Generate daily weather & NDVI for 2016‚Äì2025\n",
    "weather_daily = generate_daily_weather(geo_df, 2016, 2025)\n",
    "\n",
    "# 3) Aggregate to seasonal summaries and synthesize yearly crop yields\n",
    "seasonal = build_seasonal_summaries(weather_daily)\n",
    "yields_yearly = synthesize_yields(seasonal)\n",
    "\n",
    "# 4) Save base datasets ‚Äî üëá all paths now built using os.path.join\n",
    "weather_csv = os.path.join(\".\", OUTDIR, \"au_crop_weather_daily.csv\")\n",
    "yields_csv  = os.path.join(\".\", OUTDIR, \"au_crop_yields_yearly.csv\")\n",
    "weather_daily.to_csv(weather_csv, index=False)\n",
    "yields_yearly.to_csv(yields_csv, index=False)\n",
    "print(f\"‚úì Saved: {weather_csv}\")\n",
    "print(f\"‚úì Saved: {yields_csv}\")\n",
    "\n",
    "# 5) Fit weekly simple linear models (single predictor) and build plot_df with 'unit'\n",
    "metrics_df, plot_df = fit_models(weather_daily, yields_yearly)\n",
    "\n",
    "# 6) Save model outputs (full metrics + plotting dataset)\n",
    "metrics_csv = os.path.join(\".\", OUTDIR, \"model_weekly_metrics_allsets.csv\")\n",
    "plot_csv    = os.path.join(\".\", OUTDIR, \"model_weekly_metrics_and_forecasts.csv\")\n",
    "metrics_df.to_csv(metrics_csv, index=False)\n",
    "plot_df.to_csv(plot_csv, index=False)\n",
    "print(f\"‚úì Saved: {metrics_csv}\")\n",
    "print(f\"‚úì Saved: {plot_csv}\")\n",
    "\n",
    "# 7) Launch dashboard (inline in Jupyter or local server)\n",
    "# try:\n",
    "#     from jupyter_dash import JupyterDash\n",
    "#     app = build_dashboard(plot_df)\n",
    "#     app.__class__ = JupyterDash\n",
    "#     display(app.run(mode=\"inline\", height=900, port=8050))\n",
    "# except Exception as e:\n",
    "#     print(\"Inline mode not available; starting a local server instead...\")\n",
    "#     app = build_dashboard(plot_df)\n",
    "#     app.run(debug=False, port=8050)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b2d56605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x16cd2ac90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Launch dashboard\n",
    "launch_dashboard_in_browser(plot_df)  # opens http://127.0.0.1:8050 in your browser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb2671f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
